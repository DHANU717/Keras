{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras \"Tutorial\" Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Importing the libraries and modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import numpy\n",
    "import numpy as np\n",
    "np.random.seed(1)  # for reproducibility\n",
    "# Import warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Keras Model Module sequential\n",
    "from keras.models import Sequential\n",
    "# import Keras core layers\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "# import Keras CNN Layers\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "# import Utilities Layers for data transformation\n",
    "from keras.utils import np_utils\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FASHION-MNIST DATA\n",
    "\n",
    "The ‘Fashion-MNIST’ data set contains 60K gray-scaled images of labeled fashion categories from Zalando articles. It is also used to benchmark machine learning algorithms for image classification.\n",
    "\n",
    "The label codes are as follows:\n",
    "\n",
    "| Level    | Description   |\n",
    "|----------|---------------|\n",
    "|     0    |  T-Shirt/top  |    \n",
    "|     1    |  Trouser      |    \n",
    "|     2    |  Pullover     | \n",
    "|     3    |  Dress        |\n",
    "|     4    |  Coat         |\n",
    "|     5    |  Sandal       |\n",
    "|     6    |  Shirt        |\n",
    "|     7    |  Sneaker      |\n",
    "|     8    |  Bag          |\n",
    "|     9    |  Ankle boot   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/30393611/78396744-e2a5b200-75bd-11ea-9ffd-fa2b48c9f4b1.png\" alt=\"iamge Neural_Net\" align=\"center\" height=\"400\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before processing data, lets have a look at the shape of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's appear that there are 60,000 sample of images in the training set, each and every images are of size 28*28 pixels.\n",
    "\n",
    "Let's confirm that we have the images intact by printing out the first image. In python, images are printed out using the package called matplotlib. So we will print it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  9\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.show()\n",
    "print(\"Label: \", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data before doing using any alogorithm is a kind of sanity check it helps to get knowledge about the dimensions of data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Preprocess input data for Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tensorflow the ordering is (shape, cols, rows, depth)\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to get it verified whether it's worked correctly or not, we will print out the shape of the image. Although we have mentioned the pixels as hard coded it's better to have it as a dynamic value that got from the image. If the images are of different pixels notation then try running a loop for each and every images in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that the dimensions have changed clearly and depth has been added to the shape notation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final preprocessing step for the input data is to convert our data type to float32 and normalize our data values to the range [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to of type Float since on scaling from \n",
    "# 0 to 1 we might be looking at decimal values\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# Scaling it from 0 to 1\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus all the pre-processing required for the image data is ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess class labels for Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " lets check the shape of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks problematic. We should have got 10 labels one for each labels.  And what we have is 1D arrays. So we will the labels of first training samples now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 0 3 0 2 7 2 5 5]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there's the problem. The y_train and y_test data are not split into 10 distinct class labels, but rather are represented as a single array with the class values. We can solve with few lines of manupulating code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 1D to 10D class labels similar to converting to catergorical variable\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular neural networks are composed of sequential layers, and work roughly as follows:\n",
    "\n",
    "-  Data is fed into an **input layer** of neurons, typically in the shape of the data itself. \n",
    "-  The data is fed forward through one or more **hidden layers**, of a chosen size.\n",
    "-  A final **output layer** consists of one neuron for each class designation, one of which is activated by the final calculus of the network based on an individual input.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/30393611/78395173-03203d00-75bb-11ea-92be-2c115aa4f8b3.png\" alt=\"iamge Neural_Net\" align=\"center\" height=\"400\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Every neuron in the network starts with a **weight** and **bias** with which it transforms incoming data. Most often these are initialized arbitrarily. \n",
    "-  After a certain number of individuals in the training data (called a **batch**) have been fed through the system this way, the neural net compares its classification predictions (more accurately, it's prediction probabilities) to the true class values (1 for the correct answer, 0 for everything else). The neural net then **backpropagates**, adjusting the **weights** and **biases** of each neuron so as to minimize its predictive error relative to the correct values. Different loss functions can be minimized depending on the purpose of the network, in this case we will minimize **categorical cross-entropy**, a loss function designed for multi-class classification, with especially strong penalties for confidently incorrect predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/30393611/78398359-f43c8900-75c0-11ea-87c0-3dc9f97d4762.png\" alt=\"iamge Neural_Net\" align=\"center\" height=\"400\" width=\"600\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, after making data ready for using in an algorithm,  we are ready to define model archetecture. First we have define the model before training the data. Keras and tensorflow has lots of support that it offers for this process. Let's start by declaring a sequential model format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to define the input layer of the neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dharmendra/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "cnn.add(Convolution2D(27, 3, 3, activation='relu', input_shape=(28,28,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the first hidden layer.\n",
    "The input parameter is of the notation (depth, width, height) and this case we see that the depth is 1(2D image) and width and height is 28 pixels each. The first 3 parameters represent the number of convolution filters to use, the number of rows in each convolution kernel, and the number of columns in each convolution kernel, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm whether it has worked fine by printing the shape of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 26, 26, 27)\n"
     ]
    }
   ],
   "source": [
    "print(cnn.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add more layers of neurons. Further, here we are using simple and powerful **regularization** technique for neural networks and deep learning models is **dropout**. Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped-out” randomly. \n",
    "\n",
    "Adding dropout layer with 50% probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(Convolution2D(27, 3, 3, activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "cnn.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the basics setup, we will just make a fully connected dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected dense layer of the net\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(100, activation='relu'))\n",
    "cnn.add(Dropout(0.5))\n",
    "cnn.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And thus we have our convolution neural net that is up and ready to take it data to do the deep learning magic. Now we all need is to define the loss function and the optimizer and we ready to train the net with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have defined our model and now we just have few more simple steps away from our convolution net. Now, lets complie the model and train the data. And when we are compling the data we will do the optimizer and loss function of our net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that keras do have more loss and optimizer that is in tact with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model on the train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets fit the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/dharmendra/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 107s 2ms/step - loss: 0.5617 - accuracy: 0.7972\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.3982 - accuracy: 0.8573\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 108s 2ms/step - loss: 0.3524 - accuracy: 0.8726\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.3233 - accuracy: 0.8809\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 107s 2ms/step - loss: 0.3007 - accuracy: 0.8901\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.2863 - accuracy: 0.8955\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.2748 - accuracy: 0.9002\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 110s 2ms/step - loss: 0.2613 - accuracy: 0.9040\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 111s 2ms/step - loss: 0.2558 - accuracy: 0.9060\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 112s 2ms/step - loss: 0.2479 - accuracy: 0.9081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f19fe3bf4a8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the data\n",
    "cnn.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,we used only 10 epoch to reduce computaional time, it can be increased or decreased if necessary. Further, we can use a variety of callbacks to set early-stopping rules, save model weights along the way, or log the history of each training epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our model is trained. Now lets validate it over the new data. For this purpose only we have already split the dataset into train and test. So we now use the test data to evaluate our model and see the metrics on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "score = cnn.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have test evaluation score. lets print it to see the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.92\n",
      "Error is  0.23\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy is \", round(score[1], 2))\n",
    "print(\"Error is \", round(score[0], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a 92% accurate neral network that could perform well in identifying the items in fashion minst data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
